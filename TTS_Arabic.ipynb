{"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"12Z2Pzv9eP_jXDX45YXJMyI8PMhSOnQX_","timestamp":1715437596450}]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8248484,"sourceType":"datasetVersion","datasetId":4893951}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Cloning github repositry that contains Tacotron 2\n","metadata":{"id":"gIvWSW6OeVjv"}},{"cell_type":"code","source":"import os\nos.chdir('/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2024-05-12T19:31:09.590124Z","iopub.execute_input":"2024-05-12T19:31:09.590765Z","iopub.status.idle":"2024-05-12T19:31:09.601430Z","shell.execute_reply.started":"2024-05-12T19:31:09.590730Z","shell.execute_reply":"2024-05-12T19:31:09.600504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/Fadi-S/tts-arabic-pytorch","metadata":{"id":"vzmWGyS9vw1V","executionInfo":{"status":"ok","timestamp":1710527763709,"user_tz":-120,"elapsed":875,"user":{"displayName":"Balbatooz","userId":"13930225969742395979"}},"outputId":"570969ce-3db8-42ee-bcce-a1d1b78621dc","execution":{"iopub.status.busy":"2024-05-12T19:31:10.897642Z","iopub.execute_input":"2024-05-12T19:31:10.898433Z","iopub.status.idle":"2024-05-12T19:31:11.845618Z","shell.execute_reply.started":"2024-05-12T19:31:10.898404Z","shell.execute_reply":"2024-05-12T19:31:11.844700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd tts-arabic-pytorch && git pull origin master","metadata":{"execution":{"iopub.status.busy":"2024-05-12T19:31:11.847496Z","iopub.execute_input":"2024-05-12T19:31:11.847830Z","iopub.status.idle":"2024-05-12T19:31:13.697309Z","shell.execute_reply.started":"2024-05-12T19:31:11.847802Z","shell.execute_reply":"2024-05-12T19:31:13.696304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2024-05-12T19:12:17.484406Z","iopub.execute_input":"2024-05-12T19:12:17.484713Z","iopub.status.idle":"2024-05-12T19:12:30.486638Z","shell.execute_reply.started":"2024-05-12T19:12:17.484685Z","shell.execute_reply":"2024-05-12T19:12:30.485524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Downloading Pretrained model","metadata":{"id":"dfTvQNsXfAze"}},{"cell_type":"code","source":"import gdown\n\nurl = 'https://drive.google.com/uc?id=1FD2J-xUk48JPF9TeS8ZKHzDC_ZNBfLd8'\n\noutput = '/kaggle/working/'\n\ngdown.download(url, output, quiet=False)","metadata":{"id":"aZGSd4wOkMQy","executionInfo":{"status":"ok","timestamp":1710527781597,"user_tz":-120,"elapsed":8923,"user":{"displayName":"Balbatooz","userId":"13930225969742395979"}},"outputId":"270a68be-cae3-4318-a13f-a85b081265d5","execution":{"iopub.status.busy":"2024-05-12T19:12:30.489097Z","iopub.execute_input":"2024-05-12T19:12:30.489379Z","iopub.status.idle":"2024-05-12T19:12:38.795693Z","shell.execute_reply.started":"2024-05-12T19:12:30.489353Z","shell.execute_reply":"2024-05-12T19:12:38.794659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip -o ar-tts-models.zip -d tts-arabic-pytorch/pretrained/","metadata":{"id":"BYbN8yFRlEJg","executionInfo":{"status":"ok","timestamp":1710527884334,"user_tz":-120,"elapsed":102739,"user":{"displayName":"Balbatooz","userId":"13930225969742395979"}},"outputId":"64d415a4-62a8-4957-da5e-7e60203931e1","execution":{"iopub.status.busy":"2024-05-12T19:12:38.796793Z","iopub.execute_input":"2024-05-12T19:12:38.797165Z","iopub.status.idle":"2024-05-12T19:12:46.327074Z","shell.execute_reply.started":"2024-05-12T19:12:38.797142Z","shell.execute_reply":"2024-05-12T19:12:46.326181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir('/kaggle/working/tts-arabic-pytorch')","metadata":{"execution":{"iopub.status.busy":"2024-05-12T19:31:19.812558Z","iopub.execute_input":"2024-05-12T19:31:19.813488Z","iopub.status.idle":"2024-05-12T19:31:19.818033Z","shell.execute_reply.started":"2024-05-12T19:31:19.813454Z","shell.execute_reply":"2024-05-12T19:31:19.816940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndataset_path = '/kaggle/input/egyptian-arabic-wavs'\n\n# Load the index.csv file into a DataFrame\ndata = pd.read_csv('/kaggle/input/egyptian-arabic-wavs/index.csv')\n\nfiles_list = os.listdir(\"/kaggle/input/egyptian-arabic-wavs/data\")\nfiles_dict = {file_name: True for file_name in files_list}\n\ndata['file_exists'] = data['audio_file'].apply(lambda x: x in files_dict)\n\ndata = data[data['file_exists'] == True]\n\naudio_files = data['audio_file']\ntexts = data['text']\n\n# Display the contents of index.csv\nprint(data.head())","metadata":{"id":"XKyioS1LmZOu","execution":{"iopub.status.busy":"2024-05-12T19:32:23.314674Z","iopub.execute_input":"2024-05-12T19:32:23.315519Z","iopub.status.idle":"2024-05-12T19:32:23.735249Z","shell.execute_reply.started":"2024-05-12T19:32:23.315487Z","shell.execute_reply":"2024-05-12T19:32:23.734356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\n# Split the data into training and validation sets\ntrain_audio_files, val_audio_files, train_texts, val_texts = train_test_split(audio_files, texts, test_size=0.2, random_state=42)\n\ntrain_data = pd.DataFrame({'filename': train_audio_files, 'text': train_texts})\nval_data = pd.DataFrame({'filename': val_audio_files, 'text': val_texts})","metadata":{"execution":{"iopub.status.busy":"2024-05-12T19:32:27.396012Z","iopub.execute_input":"2024-05-12T19:32:27.396633Z","iopub.status.idle":"2024-05-12T19:32:27.414737Z","shell.execute_reply.started":"2024-05-12T19:32:27.396599Z","shell.execute_reply":"2024-05-12T19:32:27.413994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.DataFrame(train_data, columns=['filename', 'text'])\nval_data = pd.DataFrame(val_data, columns=['filename', 'text'])\n\n# Display the data frame\ntrain_data.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T19:32:29.904838Z","iopub.execute_input":"2024-05-12T19:32:29.905194Z","iopub.status.idle":"2024-05-12T19:32:29.916787Z","shell.execute_reply.started":"2024-05-12T19:32:29.905166Z","shell.execute_reply":"2024-05-12T19:32:29.915813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing Text","metadata":{"id":"Qu_PRJoG2Pvw"}},{"cell_type":"code","source":"import text\n\ndef preprocess(txt):\n    txt = txt.replace(\".\", \"\")\n    txt = txt.replace(\"!\", \"\")\n    txt = txt.replace(\",\", \"\")\n    t_phon = text.arabic_to_buckwalter(txt)\n    t_phon = text.buckwalter_to_phonemes(t_phon)\n    return t_phon","metadata":{"id":"SmRlJl79j8S0","execution":{"iopub.status.busy":"2024-05-12T19:32:31.600827Z","iopub.execute_input":"2024-05-12T19:32:31.601192Z","iopub.status.idle":"2024-05-12T19:32:31.612926Z","shell.execute_reply.started":"2024-05-12T19:32:31.601164Z","shell.execute_reply":"2024-05-12T19:32:31.612054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_phonemes,val_phonemes = [], []\n\nfor _, row in train_data.iterrows():\n    train_phonemes.append(preprocess(row['text']))\n\nfor _,row in val_data.iterrows():\n    val_phonemes.append(preprocess(row['text']))","metadata":{"id":"3fHUBWQx3GSi","execution":{"iopub.status.busy":"2024-05-12T19:32:32.013248Z","iopub.execute_input":"2024-05-12T19:32:32.013868Z","iopub.status.idle":"2024-05-12T19:32:44.298887Z","shell.execute_reply.started":"2024-05-12T19:32:32.013837Z","shell.execute_reply":"2024-05-12T19:32:44.298041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.assign(Phonemes=train_phonemes)\nval_data = val_data.assign(Phonemes=val_phonemes)","metadata":{"id":"DpASMJYEalQX","execution":{"iopub.status.busy":"2024-05-12T19:32:44.300412Z","iopub.execute_input":"2024-05-12T19:32:44.300713Z","iopub.status.idle":"2024-05-12T19:32:44.311477Z","shell.execute_reply.started":"2024-05-12T19:32:44.300689Z","shell.execute_reply":"2024-05-12T19:32:44.310590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.drop('text', axis=1)\nval_data = val_data.drop('text', axis=1)","metadata":{"id":"AzIMzVFdnw_8","execution":{"iopub.status.busy":"2024-05-12T19:32:44.312628Z","iopub.execute_input":"2024-05-12T19:32:44.312979Z","iopub.status.idle":"2024-05-12T19:32:44.327122Z","shell.execute_reply.started":"2024-05-12T19:32:44.312946Z","shell.execute_reply":"2024-05-12T19:32:44.326356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1703769790985,"user":{"displayName":"Balbatooz","userId":"13930225969742395979"},"user_tz":-120},"id":"XbWfDyxUzJYH","outputId":"e43d6426-0980-40ff-ea15-9149de010362","execution":{"iopub.status.busy":"2024-05-12T19:32:44.329858Z","iopub.execute_input":"2024-05-12T19:32:44.331065Z","iopub.status.idle":"2024-05-12T19:32:44.340466Z","shell.execute_reply.started":"2024-05-12T19:32:44.331039Z","shell.execute_reply":"2024-05-12T19:32:44.339612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\n\ntrain_data.to_csv('/kaggle/working/ready_train.txt', sep=' ', header=None, index=None, quoting=csv.QUOTE_NONNUMERIC)\nval_data.to_csv('/kaggle/working/ready_val.txt', sep=' ', header=None, index=None, quoting=csv.QUOTE_NONNUMERIC)","metadata":{"id":"4yDerzogycvl","execution":{"iopub.status.busy":"2024-05-12T19:32:44.341592Z","iopub.execute_input":"2024-05-12T19:32:44.341918Z","iopub.status.idle":"2024-05-12T19:32:44.514621Z","shell.execute_reply.started":"2024-05-12T19:32:44.341888Z","shell.execute_reply":"2024-05-12T19:32:44.513838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing Audio files","metadata":{"id":"9coFqgjc2q_0"}},{"cell_type":"code","source":"#reading path for wav dataset\ntrain_path = \"/kaggle/input/egyptian-arabic-wavs/data/\"\nval_path = \"/kaggle/input/egyptian-arabic-wavs/data/\"","metadata":{"id":"Hq2Dv2itA9uv","execution":{"iopub.status.busy":"2024-05-12T19:32:44.515876Z","iopub.execute_input":"2024-05-12T19:32:44.516487Z","iopub.status.idle":"2024-05-12T19:32:44.520843Z","shell.execute_reply.started":"2024-05-12T19:32:44.516452Z","shell.execute_reply":"2024-05-12T19:32:44.519934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from utils.data import ArabDataset\n\ntrain_dataset = ArabDataset('/kaggle/working/ready_train.txt', train_path)\ntest_dataset = ArabDataset('/kaggle/working/ready_val.txt', val_path)","metadata":{"id":"3YTadTwXoazw","execution":{"iopub.status.busy":"2024-05-12T19:32:44.521959Z","iopub.execute_input":"2024-05-12T19:32:44.522272Z","iopub.status.idle":"2024-05-12T19:33:39.516652Z","shell.execute_reply.started":"2024-05-12T19:32:44.522243Z","shell.execute_reply":"2024-05-12T19:33:39.515770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FineTuning model","metadata":{"id":"CFtmAG9zsYg7"}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport random\nfrom utils.training import batch_to_device, save_states\n\n@torch.inference_mode()\ndef validate(model, test_loader, writer, device, n_iter):\n    loss_sum = 0\n    n_test_sum = 0\n\n    model.eval()\n\n    for batch in test_loader:\n        text_padded, input_lengths, mel_padded, gate_padded, \\\n            output_lengths = batch_to_device(batch, device)\n\n        y_pred = model(text_padded, input_lengths,\n                       mel_padded, output_lengths,\n                       torch.zeros_like(output_lengths))\n        mel_out, mel_out_postnet, gate_pred, alignments = y_pred\n\n        mel_loss = F.mse_loss(mel_out, mel_padded) + \\\n            F.mse_loss(mel_out_postnet, mel_padded)\n        gate_loss = F.binary_cross_entropy_with_logits(gate_pred, gate_padded)\n        loss = mel_loss + gate_loss\n\n        loss_sum += mel_padded.size(0)*loss.item()\n        n_test_sum += mel_padded.size(0)\n\n    val_loss = loss_sum / n_test_sum\n\n    idx = random.randint(0, mel_padded.size(0) - 1)\n    mel_infer, *_ = model.infer(\n        text_padded[idx:idx+1], input_lengths[idx:idx+1]*0, input_lengths[idx:idx+1])\n\n    writer.add_sample(\n        alignments[idx, :, :input_lengths[idx].item()],\n        mel_out[idx], mel_padded[idx], mel_infer[0],\n        output_lengths[idx], n_iter)\n\n    writer.add_scalar('loss/val_loss', val_loss, n_iter)\n\n    model.train()\n\n    return val_loss\n\ndef training_loop(model,\n                  optimizer,\n                  train_loader,\n                  test_loader,\n                  writer,\n                  device,\n                  config,\n                  n_epoch,\n                  n_iter):\n\n    model.train()\n    net_config = {'n_mel_channels': 80,\n              'n_symbols': 148,\n              'padding_idx': 0,\n              'symbols_embedding_dim': 384,\n              'in_fft_n_layers': 6,\n              'in_fft_n_heads': 1,\n              'in_fft_d_head': 64,\n              'in_fft_conv1d_kernel_size': 3,\n              'in_fft_conv1d_filter_size': 1536,\n              'in_fft_output_size': 384,\n              'p_in_fft_dropout': 0.1,\n              'p_in_fft_dropatt': 0.1,\n              'p_in_fft_dropemb': 0.0,\n              'out_fft_n_layers': 6,\n              'out_fft_n_heads': 1,\n              'out_fft_d_head': 64,\n              'out_fft_conv1d_kernel_size': 3,\n              'out_fft_conv1d_filter_size': 1536,\n              'out_fft_output_size': 384,\n              'p_out_fft_dropout': 0.1,\n              'p_out_fft_dropatt': 0.1,\n              'p_out_fft_dropemb': 0.0,\n              'dur_predictor_kernel_size': 3,\n              'dur_predictor_filter_size': 256,\n              'p_dur_predictor_dropout': 0.1,\n              'dur_predictor_n_layers': 2,\n              'pitch_predictor_kernel_size': 3,\n              'pitch_predictor_filter_size': 256,\n              'p_pitch_predictor_dropout': 0.1,\n              'pitch_predictor_n_layers': 2,\n              'pitch_embedding_kernel_size': 3,\n              'n_speakers': 1,\n              'speaker_emb_weight': 1.0,\n              'energy_predictor_kernel_size': 3,\n              'energy_predictor_filter_size': 256,\n              'p_energy_predictor_dropout': 0.1,\n              'energy_predictor_n_layers': 2,\n              'energy_conditioning': True,\n              'energy_embedding_kernel_size': 3}\n    for epoch in range(n_epoch, config.epochs):\n        print(f\"Epoch: {epoch}\")\n        for batch in train_loader:\n\n            text_padded, input_lengths, mel_padded, gate_padded, \\\n                output_lengths = batch_to_device(batch, device)\n            \n            # Ensure mel_padded is not empty\n            if mel_padded.numel() == 0:\n                continue\n\n            # Ensure mel_padded has at least two dimensions\n            if mel_padded.dim() < 2:\n                continue\n\n            y_pred = model(text_padded, input_lengths,\n                           mel_padded, output_lengths,\n                           torch.zeros_like(output_lengths))\n            mel_out, mel_out_postnet, gate_out, _ = y_pred\n\n            optimizer.zero_grad()\n\n            # LOSS\n            mel_loss = F.mse_loss(mel_out, mel_padded) + \\\n                F.mse_loss(mel_out_postnet, mel_padded)\n            gate_loss = F.binary_cross_entropy_with_logits(\n                gate_out, gate_padded)\n            loss = mel_loss + gate_loss\n\n            loss.backward()\n            grad_norm = torch.nn.utils.clip_grad_norm_(\n                model.parameters(), config.grad_clip_thresh)\n            optimizer.step()\n\n            # LOGGING\n            print(f\"loss: {loss.item()}, grad_norm: {grad_norm.item()}\")\n            if n_iter % config.n_save_states_iter == 0:\n                save_states(f'states.pth', model, optimizer, n_iter, epoch,\n                net_config, config)\n\n            if n_iter % config.n_save_backup_iter == 0 and n_iter > 0:\n                save_states(f'states_{n_iter}.pth', model, optimizer, n_iter, epoch,\n                net_config, config)\n\n            n_iter += 1\n\n        # VALIDATE\n        val_loss = validate(model, test_loader, writer, device, n_iter)\n        print(f\"Validation loss: {val_loss}\")\n\n\n","metadata":{"id":"6ZCm4Bz_77eV","execution":{"iopub.status.busy":"2024-05-12T19:33:57.537202Z","iopub.execute_input":"2024-05-12T19:33:57.538209Z","iopub.status.idle":"2024-05-12T19:33:57.560193Z","shell.execute_reply.started":"2024-05-12T19:33:57.538174Z","shell.execute_reply":"2024-05-12T19:33:57.559184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config(object):\n\n    def __init__ (self,batch=8, epochs = 500, grad_clip_thresh = 1.0, learning_rate = 1.0e-5, weight_decay = 1.0e-8, max_step = 3000):\n        self.epochs = epochs\n        self.grad_clip_thresh = grad_clip_thresh\n        self.learning_rate = learning_rate\n        self.weight_decay = weight_decay\n        self.max_step = max_step\n        self.batch = batch\n        self.n_save_states_iter = 100\n        self.n_save_backup_iter = 1000\n        self.checkpoint_dir = \"/kaggle/working/Checkpoint\"\n        self.pretrained_dir = \"/kaggle/working/tts-arabic-pytorch/pretrained/tacotron2_ar_adv.pth\"\n","metadata":{"id":"Rtyw3RkzSCkZ","execution":{"iopub.status.busy":"2024-05-12T19:33:58.133161Z","iopub.execute_input":"2024-05-12T19:33:58.133527Z","iopub.status.idle":"2024-05-12T19:33:58.139971Z","shell.execute_reply.started":"2024-05-12T19:33:58.133497Z","shell.execute_reply":"2024-05-12T19:33:58.139035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = config(batch=16)","metadata":{"id":"7_mwX0bIZbgj","execution":{"iopub.status.busy":"2024-05-12T19:33:58.529056Z","iopub.execute_input":"2024-05-12T19:33:58.529684Z","iopub.status.idle":"2024-05-12T19:33:58.533821Z","shell.execute_reply.started":"2024-05-12T19:33:58.529651Z","shell.execute_reply":"2024-05-12T19:33:58.532897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"states = \"/kaggle/working/Checkpoint/states.pth\"\n\nif not os.path.exists(states):\n    os.makedirs(\"/kaggle/working/Checkpoint\", exist_ok=True)\n    file = open(states, 'w')\n    file.close()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-12T19:33:59.318939Z","iopub.execute_input":"2024-05-12T19:33:59.319298Z","iopub.status.idle":"2024-05-12T19:33:59.325198Z","shell.execute_reply.started":"2024-05-12T19:33:59.319270Z","shell.execute_reply":"2024-05-12T19:33:59.323586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merges a list of samples to form a mini-batch of Tensor Used when using batched loading from a map-style dataset.\ndef text_mel_collate_fn(batch, pad_value=0):\n    input_lens_sorted, input_sort_ids = torch.sort(\n        torch.LongTensor([len(x[0]) for x in batch]),\n        dim=0, descending=True)\n    max_input_len = input_lens_sorted[0]\n\n    num_mels = batch[0][1].size(0)\n    max_target_len = max([x[1].size(1) for x in batch])\n\n    text_ids_pad = torch.LongTensor(len(batch), max_input_len)\n    mel_pad = torch.FloatTensor(len(batch), num_mels, max_target_len)\n    \n    gate_pad = torch.FloatTensor(len(batch), max_target_len)\n    output_lengths = torch.LongTensor(len(batch))\n\n    text_ids_pad.zero_(), mel_pad.fill_(pad_value), gate_pad.zero_()\n\n    for i in range(len(input_sort_ids)):\n        text_ids, mel = batch[input_sort_ids[i]]\n        text_ids_pad[i, :text_ids.size(0)] = text_ids        \n        mel_pad[i, :, :mel.size(1)] = mel\n        gate_pad[i, mel.size(1)-1:] = 1\n        output_lengths[i] = mel.size(1)\n\n    return text_ids_pad, input_lens_sorted, \\\n        mel_pad, gate_pad, output_lengths\n","metadata":{"id":"F7KhWrGp3wU2","execution":{"iopub.status.busy":"2024-05-12T19:33:59.868919Z","iopub.execute_input":"2024-05-12T19:33:59.869664Z","iopub.status.idle":"2024-05-12T19:33:59.878774Z","shell.execute_reply.started":"2024-05-12T19:33:59.869632Z","shell.execute_reply":"2024-05-12T19:33:59.877760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# dataloaders\ntrain_loader = DataLoader(train_dataset,\n                              batch_size=config.batch,\n                              collate_fn=text_mel_collate_fn,\n                              shuffle=True, drop_last=True,\n                              sampler=None)\n\ntest_loader = DataLoader(test_dataset,\n                             batch_size=config.batch, drop_last=False,\n                             shuffle=False, collate_fn=text_mel_collate_fn)","metadata":{"id":"u6MIKXHDvw7E","executionInfo":{"status":"error","timestamp":1710528012710,"user_tz":-120,"elapsed":259,"user":{"displayName":"Balbatooz","userId":"13930225969742395979"}},"outputId":"ef0392b3-0e3d-490c-e7b3-aaf8ab7a3c12","execution":{"iopub.status.busy":"2024-05-12T19:34:00.716080Z","iopub.execute_input":"2024-05-12T19:34:00.716893Z","iopub.status.idle":"2024-05-12T19:34:00.722505Z","shell.execute_reply.started":"2024-05-12T19:34:00.716858Z","shell.execute_reply":"2024-05-12T19:34:00.721327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from models.tacotron2.tacotron2_ms import Tacotron2MS\nfrom utils.logging import TBLogger\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# construct model\nmodel = Tacotron2MS(n_symbol=40)\nmodel = model.to(device)\nmodel.decoder.decoder_max_step = config.max_step\n\n# optimizer\noptimizer = torch.optim.AdamW(model.parameters(),\n                                  lr=1.0e-3,\n                                  weight_decay=config.weight_decay)\n\n# resume from existing checkpoint\nn_epoch, n_iter = 0, 0\n\n\nstate_dicts = torch.load(config.pretrained_dir)\nmodel.load_state_dict(state_dicts['model'])\nif 'optim' in state_dicts:\n      optimizer.load_state_dict(state_dicts['optim'])\nif 'epoch' in state_dicts:\n      n_epoch = state_dicts['epoch']\nif 'iter' in state_dicts:\n      n_iter = state_dicts['iter']\n\n\nwriter = TBLogger(\"checkpoints/exp_tc2_adv\")\n    # start training\ntraining_loop(model,\n                  optimizer,\n                  train_loader,\n                  test_loader,\n                  writer,\n                  device,\n                  config,\n                  n_epoch,\n                  n_iter)","metadata":{"id":"CbRGkZmP4GWX","outputId":"c3b66b96-82c8-41e6-e217-297b29f3bd58","execution":{"iopub.status.busy":"2024-05-12T19:34:02.304031Z","iopub.execute_input":"2024-05-12T19:34:02.304363Z","iopub.status.idle":"2024-05-12T19:34:02.896016Z","shell.execute_reply.started":"2024-05-12T19:34:02.304338Z","shell.execute_reply":"2024-05-12T19:34:02.894692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport IPython\nfrom models.tacotron2 import Tacotron2Wave\n\nmodel = Tacotron2Wave(\"/kaggle/working/Checkpoint/states.pth\")\nmodel = model.cuda()\n\nwave, mel_spec = model.tts(\"ازيك عامل ايه يا باشا\" ,return_mel=True, denoise=0.005)\n\nprint(\"Audio output (Tacotron2)\")\nIPython.display.Audio(data=0.5*wave, rate=44100, normalize=False)","metadata":{"executionInfo":{"elapsed":3187,"status":"ok","timestamp":1710528541663,"user":{"displayName":"Balbatooz","userId":"13930225969742395979"},"user_tz":-120},"id":"VAgQS30Q7QY8","outputId":"46769b38-99d9-49fc-f889-c0a8f4a4b518","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}