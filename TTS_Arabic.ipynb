{"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"12Z2Pzv9eP_jXDX45YXJMyI8PMhSOnQX_","timestamp":1715437596450}]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8248484,"sourceType":"datasetVersion","datasetId":4893951}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Cloning github repositry that contains Tacotron 2\n","metadata":{"id":"gIvWSW6OeVjv"}},{"cell_type":"code","source":"import os\nos.chdir('/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:16:03.554188Z","iopub.execute_input":"2024-05-13T20:16:03.554556Z","iopub.status.idle":"2024-05-13T20:16:03.566816Z","shell.execute_reply.started":"2024-05-13T20:16:03.554525Z","shell.execute_reply":"2024-05-13T20:16:03.566041Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/Fadi-S/tts-arabic-pytorch","metadata":{"id":"vzmWGyS9vw1V","executionInfo":{"status":"ok","timestamp":1710527763709,"user_tz":-120,"elapsed":875,"user":{"displayName":"Balbatooz","userId":"13930225969742395979"}},"outputId":"570969ce-3db8-42ee-bcce-a1d1b78621dc","execution":{"iopub.status.busy":"2024-05-13T19:48:51.405275Z","iopub.execute_input":"2024-05-13T19:48:51.406297Z","iopub.status.idle":"2024-05-13T19:48:52.528184Z","shell.execute_reply.started":"2024-05-13T19:48:51.406236Z","shell.execute_reply":"2024-05-13T19:48:52.526922Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"fatal: destination path 'tts-arabic-pytorch' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"!cd tts-arabic-pytorch && git pull origin master","metadata":{"execution":{"iopub.status.busy":"2024-05-13T19:48:52.530763Z","iopub.execute_input":"2024-05-13T19:48:52.531149Z","iopub.status.idle":"2024-05-13T19:48:53.960284Z","shell.execute_reply.started":"2024-05-13T19:48:52.531112Z","shell.execute_reply":"2024-05-13T19:48:53.959373Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"From https://github.com/Fadi-S/tts-arabic-pytorch\n * branch            master     -> FETCH_HEAD\nAlready up to date.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install gdown","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Downloading Pretrained model","metadata":{"id":"dfTvQNsXfAze"}},{"cell_type":"code","source":"import gdown\n\nurl = 'https://drive.google.com/uc?id=1FD2J-xUk48JPF9TeS8ZKHzDC_ZNBfLd8'\n\noutput = '/kaggle/working/'\n\ngdown.download(url, output, quiet=False)","metadata":{"id":"aZGSd4wOkMQy","executionInfo":{"status":"ok","timestamp":1710527781597,"user_tz":-120,"elapsed":8923,"user":{"displayName":"Balbatooz","userId":"13930225969742395979"}},"outputId":"270a68be-cae3-4318-a13f-a85b081265d5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip -o ar-tts-models.zip -d tts-arabic-pytorch/pretrained/","metadata":{"id":"BYbN8yFRlEJg","executionInfo":{"status":"ok","timestamp":1710527884334,"user_tz":-120,"elapsed":102739,"user":{"displayName":"Balbatooz","userId":"13930225969742395979"}},"outputId":"64d415a4-62a8-4957-da5e-7e60203931e1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir('/kaggle/working/tts-arabic-pytorch')","metadata":{"execution":{"iopub.status.busy":"2024-05-13T19:48:58.540783Z","iopub.execute_input":"2024-05-13T19:48:58.541191Z","iopub.status.idle":"2024-05-13T19:48:58.545880Z","shell.execute_reply.started":"2024-05-13T19:48:58.541141Z","shell.execute_reply":"2024-05-13T19:48:58.544957Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndataset_path = '/kaggle/input/egyptian-arabic-wavs'\n\n# Load the index.csv file into a DataFrame\ndata = pd.read_csv('/kaggle/input/egyptian-arabic-wavs/index.csv')\n\nfiles_list = os.listdir(\"/kaggle/input/egyptian-arabic-wavs/data\")\nfiles_dict = {file_name: True for file_name in files_list}\n\ndata['file_exists'] = data['audio_file'].apply(lambda x: x in files_dict)\n\ndata = data[data['file_exists'] == True]\n\naudio_files = data['audio_file']\ntexts = data['text']\n\n# Display the contents of index.csv\nprint(data.head())","metadata":{"id":"XKyioS1LmZOu","execution":{"iopub.status.busy":"2024-05-13T19:48:59.040982Z","iopub.execute_input":"2024-05-13T19:48:59.041620Z","iopub.status.idle":"2024-05-13T19:49:00.814476Z","shell.execute_reply.started":"2024-05-13T19:48:59.041587Z","shell.execute_reply":"2024-05-13T19:49:00.813291Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"     audio_file                                      text  gender  file_exists\n0  IIqfET_1.wav    ازيكم يا جماعه عاملين ايه يا رب تكونوا  female         True\n1  jGqkHh_2.wav  بخير وصحه وسعاده وهنا وكل حاجه حلوه طبعا  female         True\n2  NE6jEu_3.wav     يا جماعه شايفيني بالعبايه وبالقران دي  female         True\n3  Dmkv3J_4.wav   اعرفوا على طول ان انا كنت في السوق ولسه  female         True\n4  H4s1qn_5.wav      طالعه فال المهم يا جماعه ان انا جايه  female         True\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\n# Split the data into training and validation sets\ntrain_audio_files, val_audio_files, train_texts, val_texts = train_test_split(audio_files, texts, test_size=0.2, random_state=42)\n\ntrain_data = pd.DataFrame({'filename': train_audio_files, 'text': train_texts})\nval_data = pd.DataFrame({'filename': val_audio_files, 'text': val_texts})","metadata":{"execution":{"iopub.status.busy":"2024-05-13T19:49:00.947778Z","iopub.execute_input":"2024-05-13T19:49:00.948068Z","iopub.status.idle":"2024-05-13T19:49:01.504203Z","shell.execute_reply.started":"2024-05-13T19:49:00.948043Z","shell.execute_reply":"2024-05-13T19:49:01.503374Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data = pd.DataFrame(train_data, columns=['filename', 'text'])\nval_data = pd.DataFrame(val_data, columns=['filename', 'text'])\n\n# Display the data frame\ntrain_data.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T19:49:01.985248Z","iopub.execute_input":"2024-05-13T19:49:01.985614Z","iopub.status.idle":"2024-05-13T19:49:02.001016Z","shell.execute_reply.started":"2024-05-13T19:49:01.985587Z","shell.execute_reply":"2024-05-13T19:49:02.000109Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"              filename                                      text\n18538  CIenec_2055.wav     ابتديتها بدري قوي او ابتديت تاخدها من\n41760  4RG7rS_3318.wav    لغايه النهارده لا حقيقي والله اشهد لهم\n11015   BvhP3h_159.wav  بتدخل للمطبخ تشوف الاخطاء وكده بس قبل كل\n42713   Ua7qh3_321.wav    عزيز النهارده احنا اه يعني يمكن تعرضنا\n30385   c7xpAQ_255.wav  انا عايزك والله انا عارف ان كتير كمان من\n20706  GDNg53_1205.wav  لازم اتكلم مع الدكتور وافهم منه كويس قوي\n26901  51HH3k_3170.wav  كده كان حد عمله انت بتنزله على الجهاز بك\n12745   zkufhO_132.wav  ونبقى ونبقى صحاب اللي هو نبقى بيبتدي بقى\n2383    QpJyWS_617.wav  ا هلا عندي التزامات مطار كون اوكي بس فرق\n9039    r6Cm99_224.wav       شخص مش باين على جسمه اي اعراض واضحه","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18538</th>\n      <td>CIenec_2055.wav</td>\n      <td>ابتديتها بدري قوي او ابتديت تاخدها من</td>\n    </tr>\n    <tr>\n      <th>41760</th>\n      <td>4RG7rS_3318.wav</td>\n      <td>لغايه النهارده لا حقيقي والله اشهد لهم</td>\n    </tr>\n    <tr>\n      <th>11015</th>\n      <td>BvhP3h_159.wav</td>\n      <td>بتدخل للمطبخ تشوف الاخطاء وكده بس قبل كل</td>\n    </tr>\n    <tr>\n      <th>42713</th>\n      <td>Ua7qh3_321.wav</td>\n      <td>عزيز النهارده احنا اه يعني يمكن تعرضنا</td>\n    </tr>\n    <tr>\n      <th>30385</th>\n      <td>c7xpAQ_255.wav</td>\n      <td>انا عايزك والله انا عارف ان كتير كمان من</td>\n    </tr>\n    <tr>\n      <th>20706</th>\n      <td>GDNg53_1205.wav</td>\n      <td>لازم اتكلم مع الدكتور وافهم منه كويس قوي</td>\n    </tr>\n    <tr>\n      <th>26901</th>\n      <td>51HH3k_3170.wav</td>\n      <td>كده كان حد عمله انت بتنزله على الجهاز بك</td>\n    </tr>\n    <tr>\n      <th>12745</th>\n      <td>zkufhO_132.wav</td>\n      <td>ونبقى ونبقى صحاب اللي هو نبقى بيبتدي بقى</td>\n    </tr>\n    <tr>\n      <th>2383</th>\n      <td>QpJyWS_617.wav</td>\n      <td>ا هلا عندي التزامات مطار كون اوكي بس فرق</td>\n    </tr>\n    <tr>\n      <th>9039</th>\n      <td>r6Cm99_224.wav</td>\n      <td>شخص مش باين على جسمه اي اعراض واضحه</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Preprocessing Text","metadata":{"id":"Qu_PRJoG2Pvw"}},{"cell_type":"code","source":"import text\n\ndef preprocess(txt):\n    txt = txt.replace(\".\", \"\")\n    txt = txt.replace(\"!\", \"\")\n    txt = txt.replace(\",\", \"\")\n    t_phon = text.arabic_to_buckwalter(txt)\n    t_phon = text.buckwalter_to_phonemes(t_phon)\n    return t_phon","metadata":{"id":"SmRlJl79j8S0","execution":{"iopub.status.busy":"2024-05-13T19:49:04.429667Z","iopub.execute_input":"2024-05-13T19:49:04.430282Z","iopub.status.idle":"2024-05-13T19:49:04.442825Z","shell.execute_reply.started":"2024-05-13T19:49:04.430248Z","shell.execute_reply":"2024-05-13T19:49:04.442104Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_phonemes,val_phonemes = [], []\n\nfor _, row in train_data.iterrows():\n    train_phonemes.append(preprocess(row['text']))\n\nfor _,row in val_data.iterrows():\n    val_phonemes.append(preprocess(row['text']))","metadata":{"id":"3fHUBWQx3GSi","execution":{"iopub.status.busy":"2024-05-13T19:49:04.810224Z","iopub.execute_input":"2024-05-13T19:49:04.810519Z","iopub.status.idle":"2024-05-13T19:49:17.019904Z","shell.execute_reply.started":"2024-05-13T19:49:04.810496Z","shell.execute_reply":"2024-05-13T19:49:17.019050Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.assign(Phonemes=train_phonemes)\nval_data = val_data.assign(Phonemes=val_phonemes)","metadata":{"id":"DpASMJYEalQX","execution":{"iopub.status.busy":"2024-05-13T19:49:17.021534Z","iopub.execute_input":"2024-05-13T19:49:17.021792Z","iopub.status.idle":"2024-05-13T19:49:17.033438Z","shell.execute_reply.started":"2024-05-13T19:49:17.021768Z","shell.execute_reply":"2024-05-13T19:49:17.032396Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.drop('text', axis=1)\nval_data = val_data.drop('text', axis=1)","metadata":{"id":"AzIMzVFdnw_8","execution":{"iopub.status.busy":"2024-05-13T19:49:17.035930Z","iopub.execute_input":"2024-05-13T19:49:17.036239Z","iopub.status.idle":"2024-05-13T19:49:17.064459Z","shell.execute_reply.started":"2024-05-13T19:49:17.036214Z","shell.execute_reply":"2024-05-13T19:49:17.063612Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1703769790985,"user":{"displayName":"Balbatooz","userId":"13930225969742395979"},"user_tz":-120},"id":"XbWfDyxUzJYH","outputId":"e43d6426-0980-40ff-ea15-9149de010362","execution":{"iopub.status.busy":"2024-05-13T19:49:17.066701Z","iopub.execute_input":"2024-05-13T19:49:17.067138Z","iopub.status.idle":"2024-05-13T19:49:17.076205Z","shell.execute_reply.started":"2024-05-13T19:49:17.067106Z","shell.execute_reply":"2024-05-13T19:49:17.075122Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"              filename                                           Phonemes\n18538  CIenec_2055.wav  aa b t d ii0 t h aa + b d r ii0 + q w ii0 + uu...\n41760  4RG7rS_3318.wav  l g AA ii0 h + l n h aa r d h + l aa + H q II0...\n11015   BvhP3h_159.wav  b t d x l + l l m T b x + t $ uu0 f + l aa x T...\n42713   Ua7qh3_321.wav  E z ii0 z + l n h aa r d h + H n aa + h + ii0 ...\n30385   c7xpAQ_255.wav  aa n aa + E aa ii0 z k + w a l l h + n aa + E ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Phonemes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18538</th>\n      <td>CIenec_2055.wav</td>\n      <td>aa b t d ii0 t h aa + b d r ii0 + q w ii0 + uu...</td>\n    </tr>\n    <tr>\n      <th>41760</th>\n      <td>4RG7rS_3318.wav</td>\n      <td>l g AA ii0 h + l n h aa r d h + l aa + H q II0...</td>\n    </tr>\n    <tr>\n      <th>11015</th>\n      <td>BvhP3h_159.wav</td>\n      <td>b t d x l + l l m T b x + t $ uu0 f + l aa x T...</td>\n    </tr>\n    <tr>\n      <th>42713</th>\n      <td>Ua7qh3_321.wav</td>\n      <td>E z ii0 z + l n h aa r d h + H n aa + h + ii0 ...</td>\n    </tr>\n    <tr>\n      <th>30385</th>\n      <td>c7xpAQ_255.wav</td>\n      <td>aa n aa + E aa ii0 z k + w a l l h + n aa + E ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import csv\n\ntrain_data.to_csv('/kaggle/working/ready_train.txt', sep=' ', header=None, index=None, quoting=csv.QUOTE_NONNUMERIC)\nval_data.to_csv('/kaggle/working/ready_val.txt', sep=' ', header=None, index=None, quoting=csv.QUOTE_NONNUMERIC)","metadata":{"id":"4yDerzogycvl","execution":{"iopub.status.busy":"2024-05-13T19:49:17.077618Z","iopub.execute_input":"2024-05-13T19:49:17.078242Z","iopub.status.idle":"2024-05-13T19:49:17.251856Z","shell.execute_reply.started":"2024-05-13T19:49:17.078207Z","shell.execute_reply":"2024-05-13T19:49:17.251078Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing Audio files","metadata":{"id":"9coFqgjc2q_0"}},{"cell_type":"code","source":"#reading path for wav dataset\ntrain_path = \"/kaggle/input/egyptian-arabic-wavs/data/\"\nval_path = \"/kaggle/input/egyptian-arabic-wavs/data/\"","metadata":{"id":"Hq2Dv2itA9uv","execution":{"iopub.status.busy":"2024-05-13T19:49:17.252975Z","iopub.execute_input":"2024-05-13T19:49:17.253325Z","iopub.status.idle":"2024-05-13T19:49:17.257505Z","shell.execute_reply.started":"2024-05-13T19:49:17.253294Z","shell.execute_reply":"2024-05-13T19:49:17.256601Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from utils.data import ArabDataset\n\ntrain_dataset = ArabDataset('/kaggle/working/ready_train.txt', train_path)\ntest_dataset = ArabDataset('/kaggle/working/ready_val.txt', val_path)","metadata":{"id":"3YTadTwXoazw","execution":{"iopub.status.busy":"2024-05-13T19:49:17.258522Z","iopub.execute_input":"2024-05-13T19:49:17.258828Z","iopub.status.idle":"2024-05-13T19:52:02.367762Z","shell.execute_reply.started":"2024-05-13T19:49:17.258798Z","shell.execute_reply":"2024-05-13T19:52:02.366838Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"100%|██████████| 34652/34652 [02:07<00:00, 271.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Number of mel phonemes: 34648\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 8663/8663 [00:31<00:00, 275.01it/s]","output_type":"stream"},{"name":"stdout","text":"Number of mel phonemes: 8663\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm\n\ntrain_data_list = []\nfor i in tqdm(range(len(train_dataset))):\n    train_data_list.append(train_dataset[i])\n\n\ntest_data_list = []\nfor i in tqdm(range(len(test_dataset))):\n    test_data_list.append(test_dataset[i])","metadata":{"execution":{"iopub.status.busy":"2024-05-13T19:52:02.369578Z","iopub.execute_input":"2024-05-13T19:52:02.369999Z","iopub.status.idle":"2024-05-13T19:52:06.311079Z","shell.execute_reply.started":"2024-05-13T19:52:02.369974Z","shell.execute_reply":"2024-05-13T19:52:06.309830Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"  0%|          | 61/34648 [00:03<36:15, 15.90it/s] \n\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\ntorch.save(train_data_list, 'train_list.pt')\n\ntorch.save(test_data_list, 'test_list.pt')","metadata":{"execution":{"iopub.status.busy":"2024-05-13T02:09:29.006734Z","iopub.execute_input":"2024-05-13T02:09:29.007615Z","iopub.status.idle":"2024-05-13T02:09:57.246419Z","shell.execute_reply.started":"2024-05-13T02:09:29.007581Z","shell.execute_reply":"2024-05-13T02:09:57.245410Z"},"_kg_hide-input":false,"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from utils.audio import MelSpectrogram\nimport torchaudio\nimport torch\nimport numpy as np\n\n\ndef remove_silence(energy_per_frame: torch.Tensor, \n                   thresh: float = -10.0):\n    keep = energy_per_frame > thresh\n    # keep silence at the end\n    i = keep.size(0)-1\n    while not keep[i] and i > 0:\n        keep[i] = True\n        i -= 1\n    return keep\n\nfpath = \"/kaggle/input/egyptian-arabic-wavs/data/00WCuJ_306.wav\"\nsr_target = 22050\n\n\nmel_fn = MelSpectrogram()\nwave, sr = torchaudio.load(fpath)\nwave = wave[0].unsqueeze(0)\nprint(wave)\n\nif sr != sr_target:\n    wave = torchaudio.functional.resample(wave, sr, sr_target, 64)\n\nmel_raw = mel_fn(wave)\nmel_log = mel_raw.clamp_min(1e-5).log().squeeze()\n\nenergy_per_frame = mel_log.mean(0)\nmel_log = mel_log[:, remove_silence(energy_per_frame)]\n\nprint(mel_log)\n\nprint(test_dataset._get_mel_from_fpath(fpath))","metadata":{"execution":{"iopub.status.busy":"2024-05-13T19:52:24.102459Z","iopub.execute_input":"2024-05-13T19:52:24.103638Z","iopub.status.idle":"2024-05-13T19:52:24.215047Z","shell.execute_reply.started":"2024-05-13T19:52:24.103594Z","shell.execute_reply":"2024-05-13T19:52:24.213986Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"tensor([[-0.0123, -0.0043,  0.0137,  ..., -0.1303, -0.1714, -0.1427]])\ntensor([[-2.4934, -2.4579, -2.5453,  ..., -1.3729, -1.3529, -1.3214],\n        [-2.3956, -2.8058, -3.5942,  ..., -3.7112, -3.7404, -2.1437],\n        [-2.9601, -3.0180, -4.0359,  ..., -2.5090, -3.3230, -1.9308],\n        ...,\n        [-4.2420, -4.2018, -3.6545,  ..., -3.6895, -3.9702, -4.1281],\n        [-3.9928, -4.5492, -4.8626,  ..., -4.0606, -4.3574, -4.3361],\n        [-4.8342, -5.1724, -5.5961,  ..., -4.6302, -4.5119, -4.5136]])\ntensor([[-2.4934, -2.4579, -2.5453,  ..., -1.3729, -1.3529, -1.3214],\n        [-2.3956, -2.8058, -3.5942,  ..., -3.7112, -3.7404, -2.1437],\n        [-2.9601, -3.0180, -4.0359,  ..., -2.5090, -3.3230, -1.9308],\n        ...,\n        [-4.2420, -4.2018, -3.6545,  ..., -3.6895, -3.9702, -4.1281],\n        [-3.9928, -4.5492, -4.8626,  ..., -4.0606, -4.3574, -4.3361],\n        [-4.8342, -5.1724, -5.5961,  ..., -4.6302, -4.5119, -4.5136]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# FineTuning model","metadata":{"id":"CFtmAG9zsYg7"}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport random\nfrom utils.training import batch_to_device, save_states\nfrom tqdm import tqdm\n\n@torch.inference_mode()\ndef validate(model, test_loader, writer, device, n_iter):\n    loss_sum = 0\n    n_test_sum = 0\n\n    model.eval()\n\n    for batch in test_loader:\n        text_padded, input_lengths, mel_padded, gate_padded, \\\n            output_lengths = batch_to_device(batch, device)\n\n        y_pred = model(text_padded, input_lengths,\n                       mel_padded, output_lengths,\n                       torch.zeros_like(output_lengths))\n        mel_out, mel_out_postnet, gate_pred, alignments = y_pred\n\n        mel_loss = F.mse_loss(mel_out, mel_padded) + \\\n            F.mse_loss(mel_out_postnet, mel_padded)\n        gate_loss = F.binary_cross_entropy_with_logits(gate_pred, gate_padded)\n        loss = mel_loss + gate_loss\n\n        loss_sum += mel_padded.size(0)*loss.item()\n        n_test_sum += mel_padded.size(0)\n\n    val_loss = loss_sum / n_test_sum\n\n    idx = random.randint(0, mel_padded.size(0) - 1)\n    mel_infer, *_ = model.infer(\n        text_padded[idx:idx+1], input_lengths[idx:idx+1]*0, input_lengths[idx:idx+1])\n\n    writer.add_sample(\n        alignments[idx, :, :input_lengths[idx].item()],\n        mel_out[idx], mel_padded[idx], mel_infer[0],\n        output_lengths[idx], n_iter)\n\n    writer.add_scalar('loss/val_loss', val_loss, n_iter)\n\n    model.train()\n\n    return val_loss\n\ndef training_loop(model,\n                  optimizer,\n                  train_loader,\n                  test_loader,\n                  writer,\n                  device,\n                  config,\n                  n_epoch,\n                  n_iter):\n\n    model.train()\n    net_config = {'n_mel_channels': 80,\n              'n_symbols': 148,\n              'padding_idx': 0,\n              'symbols_embedding_dim': 384,\n              'in_fft_n_layers': 6,\n              'in_fft_n_heads': 1,\n              'in_fft_d_head': 64,\n              'in_fft_conv1d_kernel_size': 3,\n              'in_fft_conv1d_filter_size': 1536,\n              'in_fft_output_size': 384,\n              'p_in_fft_dropout': 0.1,\n              'p_in_fft_dropatt': 0.1,\n              'p_in_fft_dropemb': 0.0,\n              'out_fft_n_layers': 6,\n              'out_fft_n_heads': 1,\n              'out_fft_d_head': 64,\n              'out_fft_conv1d_kernel_size': 3,\n              'out_fft_conv1d_filter_size': 1536,\n              'out_fft_output_size': 384,\n              'p_out_fft_dropout': 0.1,\n              'p_out_fft_dropatt': 0.1,\n              'p_out_fft_dropemb': 0.0,\n              'dur_predictor_kernel_size': 3,\n              'dur_predictor_filter_size': 256,\n              'p_dur_predictor_dropout': 0.1,\n              'dur_predictor_n_layers': 2,\n              'pitch_predictor_kernel_size': 3,\n              'pitch_predictor_filter_size': 256,\n              'p_pitch_predictor_dropout': 0.1,\n              'pitch_predictor_n_layers': 2,\n              'pitch_embedding_kernel_size': 3,\n              'n_speakers': 1,\n              'speaker_emb_weight': 1.0,\n              'energy_predictor_kernel_size': 3,\n              'energy_predictor_filter_size': 256,\n              'p_energy_predictor_dropout': 0.1,\n              'energy_predictor_n_layers': 2,\n              'energy_conditioning': True,\n              'energy_embedding_kernel_size': 3}\n    for epoch in range(n_epoch, config.epochs):\n\n        with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.epochs}\", unit=\"batch\") as t:\n            for batch in t:\n\n                text_padded, input_lengths, mel_padded, gate_padded, \\\n                    output_lengths = batch_to_device(batch, device)\n\n                # Ensure mel_padded is not empty\n                if mel_padded.numel() == 0:\n                    continue\n\n                # Ensure mel_padded has at least two dimensions\n                if mel_padded.dim() < 2:\n                    continue\n\n                y_pred = model(text_padded, input_lengths,\n                               mel_padded, output_lengths,\n                               torch.zeros_like(output_lengths))\n                mel_out, mel_out_postnet, gate_out, _ = y_pred\n\n                optimizer.zero_grad()\n\n                # LOSS\n                mel_loss = F.mse_loss(mel_out, mel_padded) + \\\n                    F.mse_loss(mel_out_postnet, mel_padded)\n                gate_loss = F.binary_cross_entropy_with_logits(\n                    gate_out, gate_padded)\n                loss = mel_loss + gate_loss\n\n                loss.backward()\n                grad_norm = torch.nn.utils.clip_grad_norm_(\n                    model.parameters(), config.grad_clip_thresh)\n                optimizer.step()\n\n                # LOGGING\n                t.set_postfix(loss=loss.item(), grad_norm=grad_norm.item())\n                if n_iter % config.n_save_states_iter == 0:\n                    save_states(f'states.pth', model, optimizer, n_iter, epoch,\n                    net_config, config)\n\n                if n_iter % config.n_save_backup_iter == 0 and n_iter > 0:\n                    save_states(f'states_{n_iter}.pth', model, optimizer, n_iter, epoch,\n                    net_config, config)\n\n                n_iter += 1\n\n        # VALIDATE\n        val_loss = validate(model, test_loader, writer, device, n_iter)\n        print(f\"Validation loss: {val_loss}\")\n\n\n","metadata":{"id":"6ZCm4Bz_77eV","execution":{"iopub.status.busy":"2024-05-13T20:14:33.483315Z","iopub.execute_input":"2024-05-13T20:14:33.484023Z","iopub.status.idle":"2024-05-13T20:14:33.506368Z","shell.execute_reply.started":"2024-05-13T20:14:33.483991Z","shell.execute_reply":"2024-05-13T20:14:33.505454Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class config(object):\n\n    def __init__ (self, batch=8, epochs = 500, grad_clip_thresh = 1.0, learning_rate = 1.0e-5, weight_decay = 1.0e-8, max_step = 3000):\n        self.epochs = epochs\n        self.grad_clip_thresh = grad_clip_thresh\n        self.learning_rate = learning_rate\n        self.weight_decay = weight_decay\n        self.max_step = max_step\n        self.batch = batch\n        self.n_save_states_iter = 100\n        self.n_save_backup_iter = 1000\n        self.checkpoint_dir = \"/kaggle/working/Checkpoint\"\n        self.pretrained_dir = \"/kaggle/working/Checkpoint/kaggle/working/Checkpoint/states.pth\"\n","metadata":{"id":"Rtyw3RkzSCkZ","execution":{"iopub.status.busy":"2024-05-13T20:14:33.911141Z","iopub.execute_input":"2024-05-13T20:14:33.911765Z","iopub.status.idle":"2024-05-13T20:14:33.917800Z","shell.execute_reply.started":"2024-05-13T20:14:33.911736Z","shell.execute_reply":"2024-05-13T20:14:33.916837Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"config = config()","metadata":{"id":"7_mwX0bIZbgj","execution":{"iopub.status.busy":"2024-05-13T20:14:34.289536Z","iopub.execute_input":"2024-05-13T20:14:34.290138Z","iopub.status.idle":"2024-05-13T20:14:34.294193Z","shell.execute_reply.started":"2024-05-13T20:14:34.290106Z","shell.execute_reply":"2024-05-13T20:14:34.293202Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"#merges a list of samples to form a mini-batch of Tensor Used when using batched loading from a map-style dataset.\ndef text_mel_collate_fn(batch, pad_value=0):\n\n    input_lens_sorted, input_sort_ids = torch.sort(\n        torch.LongTensor([len(x[0]) for x in batch]),\n        dim=0, descending=True)\n    max_input_len = input_lens_sorted[0]\n\n    num_mels = batch[0][1].size(0)\n    max_target_len = max([x[1].size(1) for x in batch])\n\n    text_ids_pad = torch.LongTensor(len(batch), max_input_len)\n    mel_pad = torch.FloatTensor(len(batch), num_mels, max_target_len)\n    gate_pad = torch.FloatTensor(len(batch), max_target_len)\n    output_lengths = torch.LongTensor(len(batch))\n    \n\n    text_ids_pad.zero_(), mel_pad.fill_(pad_value), gate_pad.zero_()\n\n    for i in range(len(input_sort_ids)):\n        text_ids, mel = batch[input_sort_ids[i]]\n        text_ids_pad[i, :text_ids.size(0)] = text_ids\n        mel_pad[i, :, :mel.size(1)] = mel\n        gate_pad[i, mel.size(1)-1:] = 1\n        output_lengths[i] = mel.size(1)\n\n    return text_ids_pad, input_lens_sorted, \\\n        mel_pad, gate_pad, output_lengths\n","metadata":{"id":"F7KhWrGp3wU2","execution":{"iopub.status.busy":"2024-05-13T20:14:34.776748Z","iopub.execute_input":"2024-05-13T20:14:34.777534Z","iopub.status.idle":"2024-05-13T20:14:34.786869Z","shell.execute_reply.started":"2024-05-13T20:14:34.777506Z","shell.execute_reply":"2024-05-13T20:14:34.785993Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# dataloaders\ntrain_loader = DataLoader(train_dataset,\n                              batch_size=config.batch,\n                              collate_fn=text_mel_collate_fn,\n                              shuffle=True, drop_last=True,\n                              sampler=None)\n\ntest_loader = DataLoader(test_dataset,\n                             batch_size=config.batch, drop_last=False,\n                             shuffle=False, collate_fn=text_mel_collate_fn)","metadata":{"id":"u6MIKXHDvw7E","executionInfo":{"status":"error","timestamp":1710528012710,"user_tz":-120,"elapsed":259,"user":{"displayName":"Balbatooz","userId":"13930225969742395979"}},"outputId":"ef0392b3-0e3d-490c-e7b3-aaf8ab7a3c12","execution":{"iopub.status.busy":"2024-05-13T20:14:35.193427Z","iopub.execute_input":"2024-05-13T20:14:35.194124Z","iopub.status.idle":"2024-05-13T20:14:35.199436Z","shell.execute_reply.started":"2024-05-13T20:14:35.194094Z","shell.execute_reply":"2024-05-13T20:14:35.198480Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"!export TORCH_USE_CUDA_DSA=1","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:14:35.594983Z","iopub.execute_input":"2024-05-13T20:14:35.595830Z","iopub.status.idle":"2024-05-13T20:14:36.592184Z","shell.execute_reply.started":"2024-05-13T20:14:35.595790Z","shell.execute_reply":"2024-05-13T20:14:36.591053Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from models.tacotron2.tacotron2_ms import Tacotron2MS\nfrom utils.logging import TBLogger\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# construct model\nmodel = Tacotron2MS(n_symbol=40)\nmodel = model.to(device)\nmodel.decoder.decoder_max_step = config.max_step\n\n# optimizer\noptimizer = torch.optim.AdamW(model.parameters(),\n                                  lr=1.0e-3,\n                                  weight_decay=config.weight_decay)\n\n# resume from existing checkpoint\nn_epoch, n_iter = 0, 0\n\n\nstate_dicts = torch.load(config.pretrained_dir, map_location=device)\nmodel.load_state_dict(state_dicts['model'])\nif 'optim' in state_dicts:\n      optimizer.load_state_dict(state_dicts['optim'])\nif 'epoch' in state_dicts:\n      n_epoch = state_dicts['epoch']\nif 'iter' in state_dicts:\n      n_iter = state_dicts['iter']\n\n\nwriter = TBLogger(\"checkpoints/exp_tc2_adv\")\n    # start training\ntraining_loop(model,\n                  optimizer,\n                  train_loader,\n                  test_loader,\n                  writer,\n                  device,\n                  config,\n                  n_epoch,\n                  n_iter)","metadata":{"id":"CbRGkZmP4GWX","outputId":"c3b66b96-82c8-41e6-e217-297b29f3bd58","execution":{"iopub.status.busy":"2024-05-13T20:14:36.594357Z","iopub.execute_input":"2024-05-13T20:14:36.594667Z","iopub.status.idle":"2024-05-13T20:14:37.203765Z","shell.execute_reply.started":"2024-05-13T20:14:36.594638Z","shell.execute_reply":"2024-05-13T20:14:37.202457Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Using 2 GPUs!\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mDataParallel(model)\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241m.\u001b[39mdecoder_max_step \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mmax_step\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# optimizer\u001b[39;00m\n\u001b[1;32m     15\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m     16\u001b[0m                                   lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0e-3\u001b[39m,\n\u001b[1;32m     17\u001b[0m                                   weight_decay\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mweight_decay)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'DataParallel' object has no attribute 'decoder'"],"ename":"AttributeError","evalue":"'DataParallel' object has no attribute 'decoder'","output_type":"error"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport IPython\nfrom models.tacotron2 import Tacotron2Wave\n\nmodel = Tacotron2Wave(\"/kaggle/working/Checkpoint/states.pth\")\nmodel = model.cuda()\n\nwave, mel_spec = model.tts(\"ازيك عامل ايه يا باشا\" ,return_mel=True, denoise=0.005)\n\nprint(\"Audio output (Tacotron2)\")\nIPython.display.Audio(data=0.5*wave, rate=44100, normalize=False)","metadata":{"executionInfo":{"elapsed":3187,"status":"ok","timestamp":1710528541663,"user":{"displayName":"Balbatooz","userId":"13930225969742395979"},"user_tz":-120},"id":"VAgQS30Q7QY8","outputId":"46769b38-99d9-49fc-f889-c0a8f4a4b518","trusted":true},"execution_count":null,"outputs":[]}]}